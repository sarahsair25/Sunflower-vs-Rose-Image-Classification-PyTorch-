{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sunflower vs Rose Classification - Interactive Tutorial\n",
    "\n",
    "This notebook provides an interactive walkthrough of the flower classification project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Import custom modules\n",
    "from data_loader import DataLoader as FlowerDataLoader, create_sample_dataset\n",
    "from train import FlowerDataset, FlowerClassifier, get_transforms\n",
    "from inference import FlowerPredictor\n",
    "from utils import plot_sample_images, analyze_dataset_distribution, visualize_augmentations\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Sample Dataset\n",
    "\n",
    "For demonstration purposes, let's create a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "data_loader = FlowerDataLoader(data_dir='./data')\n",
    "data_loader.setup_directories()\n",
    "\n",
    "# Create sample images\n",
    "create_sample_dataset(data_dir='./data', num_samples=100)\n",
    "\n",
    "# Prepare dataset (split into train/val/test)\n",
    "data_loader.prepare_dataset(train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dataset distribution\n",
    "analyze_dataset_distribution('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample images\n",
    "plot_sample_images('./data', num_samples=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transforms\n",
    "train_transform, val_transform = get_transforms()\n",
    "\n",
    "# Get a sample image\n",
    "sample_image_path = list(Path('./data/processed/train/sunflowers').glob('*.jpg'))[0]\n",
    "\n",
    "# Visualize augmentations\n",
    "visualize_augmentations(sample_image_path, train_transform, num_augmentations=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data paths\n",
    "train_paths, train_labels = data_loader.get_data_paths('train')\n",
    "val_paths, val_labels = data_loader.get_data_paths('val')\n",
    "test_paths, test_labels = data_loader.get_data_paths('test')\n",
    "\n",
    "print(f\"Training samples: {len(train_paths)}\")\n",
    "print(f\"Validation samples: {len(val_paths)}\")\n",
    "print(f\"Test samples: {len(test_paths)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FlowerDataset(train_paths, train_labels, transform=train_transform)\n",
    "val_dataset = FlowerDataset(val_paths, val_labels, transform=val_transform)\n",
    "test_dataset = FlowerDataset(test_paths, test_labels, transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Denormalize for visualization\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "class_names = ['Sunflower', 'Rose']\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(images):\n",
    "        img = images[i] * std + mean\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        img_np = img.permute(1, 2, 0).numpy()\n",
    "        \n",
    "        ax.imshow(img_np)\n",
    "        ax.set_title(f'{class_names[labels[i]]}', fontsize=14, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = FlowerClassifier(pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Loop (Simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import Trainer\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(model, device, train_loader, val_loader, criterion, optimizer, scheduler)\n",
    "\n",
    "# Train model\n",
    "best_val_acc = trainer.fit(num_epochs=num_epochs, save_path='best_model.pth')\n",
    "\n",
    "print(f\"\\nBest validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training metrics\n",
    "trainer.plot_metrics(save_path='training_metrics.png')\n",
    "\n",
    "# Display the plot\n",
    "from IPython.display import Image, display\n",
    "display(Image('training_metrics.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load('best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Create trainer for test evaluation\n",
    "test_trainer = Trainer(model, device, test_loader, test_loader, criterion, None)\n",
    "test_loss, test_acc, all_preds, all_labels = test_trainer.validate()\n",
    "\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(all_labels, all_preds, class_names, save_path='confusion_matrix.png')\n",
    "\n",
    "# Display\n",
    "display(Image('confusion_matrix.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Make Predictions on New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize predictor\n",
    "predictor = FlowerPredictor('best_model.pth')\n",
    "\n",
    "# Get a test image\n",
    "test_image_path = test_paths[0]\n",
    "\n",
    "# Make prediction\n",
    "pred_class, confidence, probs = predictor.predict(test_image_path)\n",
    "\n",
    "print(f\"\\nPrediction: {pred_class}\")\n",
    "print(f\"Confidence: {confidence:.2%}\")\n",
    "print(f\"\\nProbabilities:\")\n",
    "for cls, prob in zip(class_names, probs):\n",
    "    print(f\"  {cls}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions for multiple test images\n",
    "import random\n",
    "\n",
    "sample_test_paths = random.sample(test_paths, 6)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i, (ax, img_path) in enumerate(zip(axes.flat, sample_test_paths)):\n",
    "    # Get prediction\n",
    "    pred_class, confidence, probs = predictor.predict(img_path)\n",
    "    \n",
    "    # Load and display image\n",
    "    from PIL import Image\n",
    "    img = Image.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Get true label\n",
    "    true_label = class_names[test_labels[test_paths.index(img_path)]]\n",
    "    \n",
    "    # Set title with color coding\n",
    "    color = 'green' if pred_class == true_label else 'red'\n",
    "    ax.set_title(f\"True: {true_label}\\nPred: {pred_class} ({confidence:.1%})\",\n",
    "                color=color, fontweight='bold', fontsize=12)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Model Analysis\n",
    "\n",
    "Find misclassified examples to understand model weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_misclassified_images\n",
    "\n",
    "misclassified = get_misclassified_images(model, test_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Save and Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is already saved as 'best_model.pth'\n",
    "\n",
    "# Optional: Export to ONNX format\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"flower_classifier.onnx\",\n",
    "                 input_names=['input'],\n",
    "                 output_names=['output'],\n",
    "                 dynamic_axes={'input': {0: 'batch_size'},\n",
    "                              'output': {0: 'batch_size'}})\n",
    "\n",
    "print(\"âœ“ Model exported to ONNX format: flower_classifier.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Dataset preparation and exploration\n",
    "- Data augmentation techniques\n",
    "- Model training with PyTorch\n",
    "- Model evaluation and visualization\n",
    "- Making predictions on new images\n",
    "\n",
    "You can now use this trained model to classify sunflower and rose images!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
